INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_b63f60d0fc7f2e5973225c2cb2be7ca4 NOW.

 data management

 fit pystan model
Iteration:     1 / 100000 [  0%]  (Warmup) (Chain 1)
Iteration:     1 / 100000 [  0%]  (Warmup) (Chain 0)
Iteration:     1 / 100000 [  0%]  (Warmup) (Chain 3)
Iteration:     1 / 100000 [  0%]  (Warmup) (Chain 2)
Iteration: 10000 / 100000 [ 10%]  (Warmup) (Chain 1)
Iteration: 10000 / 100000 [ 10%]  (Warmup) (Chain 3)
Iteration: 10000 / 100000 [ 10%]  (Warmup) (Chain 2)
Iteration: 10000 / 100000 [ 10%]  (Warmup) (Chain 0)
Iteration: 20000 / 100000 [ 20%]  (Warmup) (Chain 1)
Iteration: 20000 / 100000 [ 20%]  (Warmup) (Chain 3)
Iteration: 20000 / 100000 [ 20%]  (Warmup) (Chain 2)
Iteration: 20000 / 100000 [ 20%]  (Warmup) (Chain 0)
Iteration: 30000 / 100000 [ 30%]  (Warmup) (Chain 1)
Iteration: 30000 / 100000 [ 30%]  (Warmup) (Chain 3)
Iteration: 30000 / 100000 [ 30%]  (Warmup) (Chain 2)
Iteration: 30000 / 100000 [ 30%]  (Warmup) (Chain 0)
Iteration: 40000 / 100000 [ 40%]  (Warmup) (Chain 1)
Iteration: 40000 / 100000 [ 40%]  (Warmup) (Chain 3)
Iteration: 40000 / 100000 [ 40%]  (Warmup) (Chain 2)
Iteration: 40000 / 100000 [ 40%]  (Warmup) (Chain 0)
Iteration: 50000 / 100000 [ 50%]  (Warmup) (Chain 1)
Iteration: 50001 / 100000 [ 50%]  (Sampling) (Chain 1)
Iteration: 50000 / 100000 [ 50%]  (Warmup) (Chain 3)
Iteration: 50001 / 100000 [ 50%]  (Sampling) (Chain 3)
Iteration: 50000 / 100000 [ 50%]  (Warmup) (Chain 2)
Iteration: 50001 / 100000 [ 50%]  (Sampling) (Chain 2)
Iteration: 50000 / 100000 [ 50%]  (Warmup) (Chain 0)
Iteration: 50001 / 100000 [ 50%]  (Sampling) (Chain 0)
Iteration: 60000 / 100000 [ 60%]  (Sampling) (Chain 1)
Iteration: 60000 / 100000 [ 60%]  (Sampling) (Chain 2)
Iteration: 60000 / 100000 [ 60%]  (Sampling) (Chain 3)
Iteration: 60000 / 100000 [ 60%]  (Sampling) (Chain 0)
Iteration: 70000 / 100000 [ 70%]  (Sampling) (Chain 1)
Iteration: 70000 / 100000 [ 70%]  (Sampling) (Chain 2)
Iteration: 70000 / 100000 [ 70%]  (Sampling) (Chain 3)
Iteration: 70000 / 100000 [ 70%]  (Sampling) (Chain 0)
Iteration: 80000 / 100000 [ 80%]  (Sampling) (Chain 2)
Iteration: 80000 / 100000 [ 80%]  (Sampling) (Chain 1)
Iteration: 80000 / 100000 [ 80%]  (Sampling) (Chain 3)
Iteration: 80000 / 100000 [ 80%]  (Sampling) (Chain 0)
Iteration: 90000 / 100000 [ 90%]  (Sampling) (Chain 2)
Iteration: 90000 / 100000 [ 90%]  (Sampling) (Chain 1)
Iteration: 90000 / 100000 [ 90%]  (Sampling) (Chain 3)
Iteration: 100000 / 100000 [100%]  (Sampling) (Chain 2)
# 
#  Elapsed Time: 4.6 seconds (Warm-up)
#                5.54 seconds (Sampling)
#                10.14 seconds (Total)
# 
Iteration: 90000 / 100000 [ 90%]  (Sampling) (Chain 0)
Iteration: 100000 / 100000 [100%]  (Sampling) (Chain 3)
# 
#  Elapsed Time: 4.59 seconds (Warm-up)
#                5.79 seconds (Sampling)
#                10.38 seconds (Total)
# 
Iteration: 100000 / 100000 [100%]  (Sampling) (Chain 1)
# 
#  Elapsed Time: 4.35 seconds (Warm-up)
#                6.08 seconds (Sampling)
#                10.43 seconds (Total)
# 
Iteration: 100000 / 100000 [100%]  (Sampling) (Chain 0)
# 
#  Elapsed Time: 5.05 seconds (Warm-up)
#                6.57 seconds (Sampling)
#                11.62 seconds (Total)
# 
Inference for Stan model: anon_model_b63f60d0fc7f2e5973225c2cb2be7ca4.
4 chains, each with iter=100000; warmup=50000; thin=1; 
post-warmup draws per chain=50000, total post-warmup draws=200000.

             mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat
a[0]        -3.83    0.02   2.51 -10.22  -4.67  -3.23  -2.24  -1.01  25631    1.0
a[1]        -0.22  3.0e-3   0.58  -1.42   -0.6  -0.19   0.19   0.86  37207    1.0
a[2]         -2.2  4.0e-3   0.81   -4.0   -2.7  -2.14  -1.63   -0.8  41133    1.0
a[3]        -0.96  1.1e-3   0.23  -1.43  -1.11  -0.95   -0.8  -0.53  40420    1.0
a[4]        -1.65  2.4e-3   0.51  -2.76  -1.97  -1.61  -1.29  -0.77  46150    1.0
a[5]        -2.83  4.9e-3   0.98  -5.15  -3.37  -2.69  -2.14  -1.31  40384    1.0
sigma_a      3.15    0.01   1.84   1.24   2.02    2.7   3.72   7.77  30140    1.0
beta         0.07  9.8e-5   0.02   0.03   0.05   0.07   0.08    0.1  35740    1.0
lambda[0]   -3.83    0.02   2.51 -10.22  -4.67  -3.23  -2.24  -1.01  25631    1.0
lambda[1]   -3.83    0.02   2.51 -10.22  -4.67  -3.23  -2.24  -1.01  25631    1.0
lambda[2]   -3.83    0.02   2.51 -10.22  -4.67  -3.23  -2.24  -1.01  25631    1.0
lambda[3]   -3.83    0.02   2.51 -10.22  -4.67  -3.23  -2.24  -1.01  25631    1.0
lambda[4]   -3.83    0.02   2.51 -10.22  -4.67  -3.23  -2.24  -1.01  25631    1.0
lambda[5]   -3.83    0.02   2.51 -10.22  -4.67  -3.23  -2.24  -1.01  25631    1.0
lambda[6]   -3.83    0.02   2.51 -10.22  -4.67  -3.23  -2.24  -1.01  25631    1.0
lambda[7]    0.98  1.5e-3   0.34   0.28   0.76    1.0   1.22    1.6  49057    1.0
lambda[8]   -0.08  2.8e-3   0.55  -1.22  -0.44  -0.06    0.3   0.93  37642    1.0
lambda[9]    2.05  1.2e-3   0.32   1.39   1.84   2.06   2.27   2.63  66668    1.0
lambda[10]   -2.0  3.8e-3   0.79  -3.75  -2.48  -1.93  -1.45  -0.66  42165    1.0
lambda[11]   -1.6  3.5e-3   0.75  -3.27  -2.05  -1.53  -1.08  -0.35  44560    1.0
lambda[12]   0.06  3.3e-3   0.74   -1.6  -0.39   0.13   0.59   1.31  52216    1.0
lambda[13]  -1.94  3.8e-3   0.78  -3.67  -2.41  -1.87  -1.39  -0.61  42535    1.0
lambda[14]  -2.14  4.0e-3   0.81  -3.92  -2.62  -2.07  -1.57  -0.75  41463    1.0
lambda[15]  -1.67  3.6e-3   0.75  -3.35  -2.12   -1.6  -1.14  -0.41  44134    1.0
lambda[16]  -0.96  1.1e-3   0.23  -1.43  -1.11  -0.95   -0.8  -0.53  40420    1.0
lambda[17]  -0.56  7.6e-4   0.18  -0.92  -0.68  -0.56  -0.44  -0.23  53512    1.0
lambda[18]  -0.76  9.3e-4    0.2  -1.16  -0.89  -0.76  -0.62  -0.39  45347    1.0
lambda[19]  -0.96  1.1e-3   0.23  -1.43  -1.11  -0.95   -0.8  -0.53  40420    1.0
lambda[20]  -0.76  9.3e-4    0.2  -1.16  -0.89  -0.76  -0.62  -0.39  45347    1.0
lambda[21]  -0.49  7.3e-4   0.17  -0.85  -0.61  -0.49  -0.37  -0.17  56622    1.0
lambda[22]  -0.23  7.1e-4   0.18  -0.59  -0.35  -0.22   -0.1   0.11  63395    1.0
lambda[23]  -0.69  8.6e-4   0.19  -1.08  -0.82  -0.69  -0.56  -0.34  47720    1.0
lambda[24]  -0.16  7.4e-4   0.19  -0.54  -0.28  -0.16  -0.03   0.19  62581    1.0
lambda[25]  -0.69  8.6e-4   0.19  -1.08  -0.82  -0.69  -0.56  -0.34  47720    1.0
lambda[26]  -0.43  7.1e-4   0.17  -0.78  -0.54  -0.42  -0.31   -0.1  59468    1.0
lambda[27]  -0.56  7.6e-4   0.18  -0.92  -0.68  -0.56  -0.44  -0.23  53512    1.0
lambda[28]  -0.43  7.1e-4   0.17  -0.78  -0.54  -0.42  -0.31   -0.1  59468    1.0
lambda[29]  -0.96  1.1e-3   0.23  -1.43  -1.11  -0.95   -0.8  -0.53  40420    1.0
lambda[30]  -0.43  7.1e-4   0.17  -0.78  -0.54  -0.42  -0.31   -0.1  59468    1.0
lambda[31]  -0.76  9.3e-4    0.2  -1.16  -0.89  -0.76  -0.62  -0.39  45347    1.0
lambda[32]  -0.69  8.6e-4   0.19  -1.08  -0.82  -0.69  -0.56  -0.34  47720    1.0
lambda[33]  -0.29  7.0e-4   0.18  -0.65  -0.41  -0.29  -0.17   0.04  63328    1.0
lambda[34]  -0.76  9.3e-4    0.2  -1.16  -0.89  -0.76  -0.62  -0.39  45347    1.0
lambda[35]  -0.69  8.6e-4   0.19  -1.08  -0.82  -0.69  -0.56  -0.34  47720    1.0
lambda[36]  -0.29  7.0e-4   0.18  -0.65  -0.41  -0.29  -0.17   0.04  63328    1.0
lambda[37]  -0.43  7.1e-4   0.17  -0.78  -0.54  -0.42  -0.31   -0.1  59468    1.0
lambda[38]  -0.83  9.9e-4   0.21  -1.25  -0.96  -0.82  -0.68  -0.44  43364    1.0
lambda[39]  -0.63  8.1e-4   0.18   -1.0  -0.75  -0.62   -0.5  -0.29  50474    1.0
lambda[40]  -0.76  9.3e-4    0.2  -1.16  -0.89  -0.76  -0.62  -0.39  45347    1.0
lambda[41]   0.04  9.0e-4   0.21  -0.39   -0.1   0.04   0.19   0.44  56754    1.0
lambda[42]  -0.09  7.9e-4   0.19  -0.49  -0.22  -0.09   0.04   0.27  60694    1.0
lambda[43]  -0.09  7.9e-4   0.19  -0.49  -0.22  -0.09   0.04   0.27  60694    1.0
lambda[44]  -0.36  6.9e-4   0.17  -0.71  -0.47  -0.36  -0.24  -0.04  61857    1.0
lambda[45]  -0.49  7.3e-4   0.17  -0.85  -0.61  -0.49  -0.37  -0.17  56622    1.0
lambda[46]   0.04  9.0e-4   0.21  -0.39   -0.1   0.04   0.19   0.44  56754    1.0
lambda[47]  -0.76  9.3e-4    0.2  -1.16  -0.89  -0.76  -0.62  -0.39  45347    1.0
lambda[48]  -0.63  8.1e-4   0.18   -1.0  -0.75  -0.62   -0.5  -0.29  50474    1.0
lambda[49]  -0.83  9.9e-4   0.21  -1.25  -0.96  -0.82  -0.68  -0.44  43364    1.0
lambda[50]  -0.56  7.6e-4   0.18  -0.92  -0.68  -0.56  -0.44  -0.23  53512    1.0
lambda[51]  -0.49  7.3e-4   0.17  -0.85  -0.61  -0.49  -0.37  -0.17  56622    1.0
lambda[52]  -0.76  9.3e-4    0.2  -1.16  -0.89  -0.76  -0.62  -0.39  45347    1.0
lambda[53]  -0.56  7.6e-4   0.18  -0.92  -0.68  -0.56  -0.44  -0.23  53512    1.0
lambda[54]   0.64  1.6e-3   0.34  -0.03   0.41   0.64   0.87    1.3  44758    1.0
lambda[55]  -0.76  9.3e-4    0.2  -1.16  -0.89  -0.76  -0.62  -0.39  45347    1.0
lambda[56]  -0.43  7.1e-4   0.17  -0.78  -0.54  -0.42  -0.31   -0.1  59468    1.0
lambda[57]  -0.49  7.3e-4   0.17  -0.85  -0.61  -0.49  -0.37  -0.17  56622    1.0
lambda[58]  -0.89  1.1e-3   0.22  -1.34  -1.04  -0.89  -0.74  -0.48  41738    1.0
lambda[59]  -0.69  8.6e-4   0.19  -1.08  -0.82  -0.69  -0.56  -0.34  47720    1.0
lambda[60]  -0.63  8.1e-4   0.18   -1.0  -0.75  -0.62   -0.5  -0.29  50474    1.0
lambda[61]  -0.56  7.6e-4   0.18  -0.92  -0.68  -0.56  -0.44  -0.23  53512    1.0
lambda[62]  -0.56  7.6e-4   0.18  -0.92  -0.68  -0.56  -0.44  -0.23  53512    1.0
lambda[63]  -0.56  7.6e-4   0.18  -0.92  -0.68  -0.56  -0.44  -0.23  53512    1.0
lambda[64]  -0.76  9.3e-4    0.2  -1.16  -0.89  -0.76  -0.62  -0.39  45347    1.0
lambda[65]  -0.23  7.1e-4   0.18  -0.59  -0.35  -0.22   -0.1   0.11  63395    1.0
lambda[66]  -0.29  7.0e-4   0.18  -0.65  -0.41  -0.29  -0.17   0.04  63328    1.0
lambda[67]  -0.63  8.1e-4   0.18   -1.0  -0.75  -0.62   -0.5  -0.29  50474    1.0
lambda[68]  -0.43  7.1e-4   0.17  -0.78  -0.54  -0.42  -0.31   -0.1  59468    1.0
lambda[69]  -0.36  6.9e-4   0.17  -0.71  -0.47  -0.36  -0.24  -0.04  61857    1.0
lambda[70]  -1.65  2.4e-3   0.51  -2.76  -1.97  -1.61  -1.29  -0.77  46150    1.0
lambda[71]  -1.65  2.4e-3   0.51  -2.76  -1.97  -1.61  -1.29  -0.77  46150    1.0
lambda[72]  -1.12  2.3e-3   0.51  -2.22  -1.43  -1.08  -0.76  -0.24  48222    1.0
lambda[73]  -1.12  2.3e-3   0.51  -2.22  -1.43  -1.08  -0.76  -0.24  48222    1.0
lambda[74]  -1.32  2.3e-3    0.5  -2.41  -1.63  -1.28  -0.97  -0.45  47728    1.0
lambda[75]  -1.39  2.3e-3    0.5  -2.48   -1.7  -1.35  -1.03  -0.52  47477    1.0
lambda[76]  -1.32  2.3e-3    0.5  -2.41  -1.63  -1.28  -0.97  -0.45  47728    1.0
lambda[77]  -1.39  2.3e-3    0.5  -2.48   -1.7  -1.35  -1.03  -0.52  47477    1.0
lambda[78]  -1.59  2.4e-3   0.51  -2.69   -1.9  -1.55  -1.23  -0.71  46521    1.0
lambda[79]  -1.52  2.3e-3   0.51  -2.62  -1.83  -1.48  -1.16  -0.64  46869    1.0
lambda[80]  -1.65  2.4e-3   0.51  -2.76  -1.97  -1.61  -1.29  -0.77  46150    1.0
lambda[81]  -1.52  2.3e-3   0.51  -2.62  -1.83  -1.48  -1.16  -0.64  46869    1.0
lambda[82]  -1.12  2.3e-3   0.51  -2.22  -1.43  -1.08  -0.76  -0.24  48222    1.0
lambda[83]  -0.99  2.3e-3   0.51   -2.1   -1.3  -0.95  -0.63   -0.1  48333    1.0
lambda[84]  -1.52  2.3e-3   0.51  -2.62  -1.83  -1.48  -1.16  -0.64  46869    1.0
lambda[85]  -2.63  4.9e-3   0.98  -4.94  -3.17  -2.49  -1.94  -1.11  40657    1.0
lambda[86]  -2.76  4.9e-3   0.98  -5.08   -3.3  -2.62  -2.07  -1.24  40478    1.0
lambda[87]   -2.7  4.9e-3   0.98  -5.01  -3.23  -2.56   -2.0  -1.18  40569    1.0
lambda[88]  -2.76  4.9e-3   0.98  -5.08   -3.3  -2.62  -2.07  -1.24  40478    1.0
lambda[89]  -2.83  4.9e-3   0.98  -5.15  -3.37  -2.69  -2.14  -1.31  40384    1.0
lambda[90]  -2.76  4.9e-3   0.98  -5.08   -3.3  -2.62  -2.07  -1.24  40478    1.0
lambda[91]  -2.56  4.9e-3   0.98  -4.87   -3.1  -2.42  -1.87  -1.05  40742    1.0
lambda[92]   -2.5  4.9e-3   0.98   -4.8  -3.03  -2.36  -1.81  -0.98  40823    1.0
lambda[93]  -2.63  4.9e-3   0.98  -4.94  -3.17  -2.49  -1.94  -1.11  40657    1.0
lambda[94]   -2.7  4.9e-3   0.98  -5.01  -3.23  -2.56   -2.0  -1.18  40569    1.0
lambda[95]   -2.7  4.9e-3   0.98  -5.01  -3.23  -2.56   -2.0  -1.18  40569    1.0
lambda[96]  -2.63  4.9e-3   0.98  -4.94  -3.17  -2.49  -1.94  -1.11  40657    1.0
lambda[97]   -2.7  4.9e-3   0.98  -5.01  -3.23  -2.56   -2.0  -1.18  40569    1.0
lambda[98]  -2.76  4.9e-3   0.98  -5.08   -3.3  -2.62  -2.07  -1.24  40478    1.0
lambda[99]  -2.83  4.9e-3   0.98  -5.15  -3.37  -2.69  -2.14  -1.31  40384    1.0
lp__        -66.2    0.01   2.23 -71.51 -67.45 -65.84 -64.57 -62.93  32632    1.0

Samples were drawn using NUTS(diag_e) at Wed Jan  6 18:05:48 2016.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
plot fit figure
